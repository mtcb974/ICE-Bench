#!/usr/bin/env python3
import json
import time
from pathlib import Path
from typing import List
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed

# å‡è®¾ä½ çš„JavaRepoClientåœ¨è¿™ä¸ªè·¯å¾„
from java_repo_client import JavaRepoClient


class ContainerWarmUp:
    """å®¹å™¨é¢„çƒ­ç®¡ç†å™¨"""
    
    def __init__(self, container_names: List[str], dataset_path: Path):
        self.container_names = container_names
        self.dataset_path = dataset_path
        self.clients = {}
        
        # åˆå§‹åŒ–æ‰€æœ‰å®¢æˆ·ç«¯
        print("æ­£åœ¨è¿æ¥Dockerå®¹å™¨...")
        for container_name in container_names:
            try:
                client = JavaRepoClient(container_name)
                self.clients[container_name] = client
                print(f"âœ… æˆåŠŸè¿æ¥å®¹å™¨: {container_name}")
            except Exception as e:
                print(f"âŒ è¿æ¥å®¹å™¨ {container_name} å¤±è´¥: {e}")
        
        if not self.clients:
            raise RuntimeError("æ²¡æœ‰å¯ç”¨çš„Dockerå®¹å™¨")
    
    def load_dataset(self) -> List[dict]:
        """åŠ è½½æ•°æ®é›†"""
        print(f"æ­£åœ¨åŠ è½½æ•°æ®é›†: {self.dataset_path}")
        with open(self.dataset_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…± {len(data)} æ¡æ ·æœ¬")
        return data
    
    def warm_up_container(self, container_name: str, data: List[dict]) -> int:
        """ä¸ºå•ä¸ªå®¹å™¨é¢„çƒ­"""
        client = self.clients[container_name]
        success_count = 0
        
        print(f"ğŸ”¥ å¼€å§‹é¢„çƒ­å®¹å™¨: {container_name}")
        
        for idx, item in enumerate(data):
            try:
                repo = item.get("project", "")
                func_start = item.get("func_start", 0)
                func_end = item.get("func_end", 0)
                func = item.get("func", "")
                file_path = item.get("file_path", "")
                test_start = item.get("test_start", 0)
                test_end = item.get("test_end", 0)
                test_code = item.get("test_code", "")
                test_file = item.get("test_file", "")
                test_instruction = item.get("test_instruction", "")

                # æ‰§è¡Œæµ‹è¯•æ¥è§¦å‘ä¾èµ–ä¸‹è½½
                success, log = client.safe_replace_and_test(
                    repo=repo,
                    file_path=file_path,
                    func_start=func_start,
                    func_end=func_end,
                    new_code=func,
                    test_file=test_file,
                    test_start=test_start,
                    test_end=test_end,
                    new_test=test_code,
                    test_instruction=test_instruction
                )
                
                if success:
                    success_count += 1
                
                # æ‰“å°è¿›åº¦ï¼ˆæ¯10ä¸ªæ ·æœ¬æ‰“å°ä¸€æ¬¡ï¼‰
                if (idx + 1) % 10 == 0:
                    print(f"  å®¹å™¨ {container_name}: å·²å¤„ç† {idx + 1}/{len(data)}, æˆåŠŸ: {success_count}")
                    
            except Exception as e:
                print(f"âŒ å®¹å™¨ {container_name} å¤„ç†æ ·æœ¬ {idx} æ—¶å‡ºé”™: {e}")
                continue
        
        print(f"âœ… å®¹å™¨ {container_name} é¢„çƒ­å®Œæˆï¼ŒæˆåŠŸ: {success_count}/{len(data)}")
        return success_count
    
    def warm_up_sequential(self):
        """é¡ºåºé¢„çƒ­æ‰€æœ‰å®¹å™¨"""
        data = self.load_dataset()
        total_success = 0
        
        for container_name in self.container_names:
            if container_name in self.clients:
                success_count = self.warm_up_container(container_name, data)
                total_success += success_count
            else:
                print(f"âš ï¸  è·³è¿‡æœªè¿æ¥çš„å®¹å™¨: {container_name}")
        
        print(f"\nğŸ‰ æ‰€æœ‰å®¹å™¨é¢„çƒ­å®Œæˆï¼æ€»æˆåŠŸæ ·æœ¬æ•°: {total_success}")
        return total_success
    
    def warm_up_parallel(self, max_workers: int = None):
        """å¹¶è¡Œé¢„çƒ­æ‰€æœ‰å®¹å™¨"""
        data = self.load_dataset()
        
        if max_workers is None:
            max_workers = len(self.clients)
        
        print(f"ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹å¹¶è¡Œé¢„çƒ­...")
        
        total_success = 0
        results = []
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ä¸ºæ¯ä¸ªå®¹å™¨æäº¤é¢„çƒ­ä»»åŠ¡
            future_to_container = {
                executor.submit(self.warm_up_container, container_name, data): container_name
                for container_name in self.clients.keys()
            }
            
            # æ”¶é›†ç»“æœ
            for future in tqdm(as_completed(future_to_container), total=len(future_to_container), desc="é¢„çƒ­è¿›åº¦"):
                container_name = future_to_container[future]
                try:
                    success_count = future.result()
                    results.append((container_name, success_count))
                    total_success += success_count
                except Exception as e:
                    print(f"âŒ å®¹å™¨ {container_name} é¢„çƒ­å¤±è´¥: {e}")
                    results.append((container_name, 0))
        
        # æ‰“å°æ¯ä¸ªå®¹å™¨çš„ç»“æœ
        print("\nğŸ“Š å„å®¹å™¨é¢„çƒ­ç»“æœ:")
        for container_name, success_count in results:
            print(f"  {container_name}: {success_count}/{len(data)}")
        
        print(f"\nğŸ‰ å¹¶è¡Œé¢„çƒ­å®Œæˆï¼æ€»æˆåŠŸæ ·æœ¬æ•°: {total_success}")
        return total_success


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®å‚æ•°
    CONTAINER_NAMES = [f"mrgbench_container_{i}" for i in range(1, 13)]  # 12ä¸ªå®¹å™¨
    DATASET_PATH = Path(__file__).parent / 'v3-MRGBench.json'
    
    # åˆ›å»ºé¢„çƒ­ç®¡ç†å™¨
    warm_up = ContainerWarmUp(CONTAINER_NAMES, DATASET_PATH)
    
    print("=" * 60)
    print("Dockerå®¹å™¨å†·å¯åŠ¨é¢„çƒ­å·¥å…·")
    print("=" * 60)
    print(f"å®¹å™¨æ•°é‡: {len(CONTAINER_NAMES)}")
    print(f"æ•°æ®é›†: {DATASET_PATH.name}")
    print("=" * 60)
    
    # é€‰æ‹©é¢„çƒ­æ¨¡å¼
    print("è¯·é€‰æ‹©é¢„çƒ­æ¨¡å¼:")
    print("1. å®Œæ•´é¢„çƒ­ï¼ˆæ‰€æœ‰æ ·æœ¬ï¼‰")
    print("2. å¹¶è¡Œé¢„çƒ­ï¼ˆæ‰€æœ‰æ ·æœ¬ï¼‰")
    
    choice = "2"
    
    start_time = time.time()
    
    if choice == "2":
        print("\nğŸš€ å¼€å§‹å¹¶è¡Œé¢„çƒ­...")
        total_success = warm_up.warm_up_parallel()
    else:
        print("\nğŸ¢ å¼€å§‹é¡ºåºé¢„çƒ­...")
        total_success = warm_up.warm_up_sequential()
    
    elapsed_time = time.time() - start_time
    print(f"\nâ° æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
    print(f"ğŸ“ˆ å¹³å‡æ¯ä¸ªå®¹å™¨è€—æ—¶: {elapsed_time / len(warm_up.clients):.2f} ç§’")
    
    # é¢„æœŸç»“æœæ£€æŸ¥
    expected_success = len(warm_up.load_dataset()) * len(warm_up.clients)
    print(f"ğŸ“Š é¢„æœŸæˆåŠŸæ•°: {expected_success}, å®é™…æˆåŠŸæ•°: {total_success}")
    
    if total_success >= expected_success * 0.8:  # 80%æˆåŠŸç‡è§†ä¸ºæ­£å¸¸
        print("âœ… é¢„çƒ­æˆåŠŸï¼å®¹å™¨å·²å‡†å¤‡å¥½è¿›è¡Œè¯„æµ‹")
    else:
        print("âš ï¸  é¢„çƒ­ç»“æœä¸ç†æƒ³ï¼Œè¯·æ£€æŸ¥å®¹å™¨çŠ¶æ€")


if __name__ == "__main__":
    main()